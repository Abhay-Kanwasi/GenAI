{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T08:28:20.613741Z",
     "start_time": "2025-10-02T08:28:20.597969Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class Runnable(ABC):\n",
    "\n",
    "    @abstractmethod\n",
    "    def invoke(input):\n",
    "        pass"
   ],
   "id": "af2130759ea9176a",
   "outputs": [],
   "execution_count": 233
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-02T08:28:20.633603Z",
     "start_time": "2025-10-02T08:28:20.617571Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import random\n",
    "\n",
    "class DummyLLLM(Runnable):\n",
    "    def __init__(self):\n",
    "        print(\"Initializing DummyLLLM\")\n",
    "\n",
    "    def invoke(self, prompt):\n",
    "        response_list = [\n",
    "            'This is response 1',\n",
    "            'This is response 2',\n",
    "            'This is response 3',\n",
    "        ]\n",
    "        return {'response' : random.choice(response_list)}\n",
    "\n",
    "    def predict(self, prompt):\n",
    "        response_list = [\n",
    "            'This is response 1',\n",
    "            'This is response 2',\n",
    "            'This is response 3',\n",
    "        ]\n",
    "        print('\\nWARNING: This method predict will be deprecated soon the functionality shifted to invoke method.')\n",
    "        return {'response' : f'Prompt: {prompt} Response: {random.choice(response_list)}'}"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 234
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T08:28:20.649493Z",
     "start_time": "2025-10-02T08:28:20.633603Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DummyPromptTemplate(Runnable):\n",
    "    def __init__(self, template, input_variables):\n",
    "        self.template = template\n",
    "        self.input_variables = input_variables\n",
    "\n",
    "    def invoke(self,input_dict):\n",
    "        return self.template.format(**input_dict)\n",
    "\n",
    "    def format(self, input_dict):\n",
    "        print('\\nWARNING: This method predict will be deprecated soon the functionality shifted to invoke method.')\n",
    "        return self.template.format(**input_dict)"
   ],
   "id": "e1b4f34ece98b65d",
   "outputs": [],
   "execution_count": 235
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T08:28:20.665160Z",
     "start_time": "2025-10-02T08:28:20.649493Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DummyStrOutputParser(Runnable):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def invoke(self,input_data):\n",
    "        return input_data['response']\n"
   ],
   "id": "81a06283fca8319c",
   "outputs": [],
   "execution_count": 236
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T08:28:20.681290Z",
     "start_time": "2025-10-02T08:28:20.665773Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class RunnableConnector(Runnable):\n",
    "    def __init__(self, runnable_list):\n",
    "        self.runnable_list = runnable_list\n",
    "\n",
    "    def invoke(self, input_data):\n",
    "        for runnable in self.runnable_list:\n",
    "            print(f'RunnableConnector Invoke: {runnable.invoke(input_data)}')\n",
    "            input_data = runnable.invoke(input_data) # Output from first runnable become input for next one\n",
    "        return input_data"
   ],
   "id": "7fba08dd76c1d414",
   "outputs": [],
   "execution_count": 237
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T08:28:20.696998Z",
     "start_time": "2025-10-02T08:28:20.681290Z"
    }
   },
   "cell_type": "code",
   "source": [
    "template = DummyPromptTemplate(\n",
    "    template='Write a {length} liner about {topic}',\n",
    "    input_variables=['length', 'topic']\n",
    ")"
   ],
   "id": "55c5ff8cc66860fb",
   "outputs": [],
   "execution_count": 238
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T08:28:20.712690Z",
     "start_time": "2025-10-02T08:28:20.696998Z"
    }
   },
   "cell_type": "code",
   "source": [
    "llm = DummyLLLM()\n",
    "parser = DummyStrOutputParser()"
   ],
   "id": "59f11ab4e05f1181",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing DummyLLLM\n"
     ]
    }
   ],
   "execution_count": 239
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T08:28:20.736088Z",
     "start_time": "2025-10-02T08:28:20.712690Z"
    }
   },
   "cell_type": "code",
   "source": "chain = RunnableConnector([template, llm, parser])",
   "id": "5f94b838261dbc0",
   "outputs": [],
   "execution_count": 240
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T08:28:20.754711Z",
     "start_time": "2025-10-02T08:28:20.738993Z"
    }
   },
   "cell_type": "code",
   "source": "chain.invoke({'length': 'one', 'topic': 'anything'})",
   "id": "7b4227e0947af096",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunnableConnector Invoke: Write a one liner about anything\n",
      "RunnableConnector Invoke: {'response': 'This is response 3'}\n",
      "RunnableConnector Invoke: This is response 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'This is response 1'"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 241
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T08:28:20.770635Z",
     "start_time": "2025-10-02T08:28:20.754711Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Example Problem: Suppose we want 2 chains one in which our LLM will create a joke and give us that joke as output. Then there will be the other chain which take jokes as input and provide explanation of joke as output. Then after creating these chains we will connect these two chains so process go like: create a joke from chain 1 give that joke to chain 2 and get the explanation of the joke.\n",
    "\n",
    "joke_template = DummyPromptTemplate(\n",
    "    template=\"Write a joke about {topic}\",\n",
    "    input_variables=['topic']\n",
    ")"
   ],
   "id": "b770913d85e0eda7",
   "outputs": [],
   "execution_count": 242
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T08:28:20.786551Z",
     "start_time": "2025-10-02T08:28:20.770635Z"
    }
   },
   "cell_type": "code",
   "source": [
    "explanation_template = DummyPromptTemplate(\n",
    "    template=\"Write a explanation about {response}\",\n",
    "    input_variables=['response']\n",
    ") # input variable will must name response because this is the key from joke template response\n",
    "llm = DummyLLLM()\n",
    "parser = DummyStrOutputParser()\n",
    "\n",
    "joke_chain = RunnableConnector([joke_template, llm])\n",
    "# joke_chain_output = joke_chain.invoke({'topic': 'anything'})\n",
    "explanation_chain = RunnableConnector([explanation_template, llm, parser])\n",
    "# explanation_chain.invoke({'joke': 'anything'})"
   ],
   "id": "459d19cd213083ed",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing DummyLLLM\n"
     ]
    }
   ],
   "execution_count": 243
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T08:28:20.811771Z",
     "start_time": "2025-10-02T08:28:20.786551Z"
    }
   },
   "cell_type": "code",
   "source": [
    "final_chain = RunnableConnector([joke_chain, explanation_chain])\n",
    "final_chain.invoke({'topic': 'anything'})"
   ],
   "id": "db0831e9913e92e9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunnableConnector Invoke: Write a joke about anything\n",
      "RunnableConnector Invoke: {'response': 'This is response 2'}\n",
      "RunnableConnector Invoke: {'response': 'This is response 3'}\n",
      "RunnableConnector Invoke: Write a joke about anything\n",
      "RunnableConnector Invoke: {'response': 'This is response 3'}\n",
      "RunnableConnector Invoke: Write a explanation about This is response 2\n",
      "RunnableConnector Invoke: {'response': 'This is response 1'}\n",
      "RunnableConnector Invoke: This is response 1\n",
      "RunnableConnector Invoke: This is response 1\n",
      "RunnableConnector Invoke: Write a explanation about This is response 2\n",
      "RunnableConnector Invoke: {'response': 'This is response 2'}\n",
      "RunnableConnector Invoke: This is response 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'This is response 3'"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 244
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
